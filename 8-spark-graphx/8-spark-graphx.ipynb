{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark graph\n",
    "\n",
    "Dans les tutoriels pr√©c√©dents nous avons toujours travaill√© avec des dataset ou table.\n",
    "\n",
    "Il existe un √©cosyst√®me spark pour traiter de gros graphes via l'api **graphx** historiquement que disponible en scala il existe **graphFrames** en python.\n",
    "\n",
    "Essayons de jouer avec cette api.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cr√©ation du context Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x7fa270555850>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import os\n",
    "\n",
    "conf = SparkConf()\n",
    "\n",
    "#url par d√©faut d'une api kubernetes acc√©d√© depuis l'int√©rieur du cluster (ici le notebook tourne lui m√™me dans kubernetes)\n",
    "conf.setMaster(\"k8s://https://kubernetes.default.svc:443\")\n",
    "\n",
    "#image des executors spark: pour des raisons de simplicit√© on r√©utilise l'image du notebook\n",
    "conf.set(\"spark.kubernetes.container.image\", \"inseefrlab/jupyter-datascience:master\")\n",
    "\n",
    "# Nom du compte de service pour contacter l'api kubernetes : attention le package du datalab cr√©e lui m√™me cette variable d'enviromment.\n",
    "# Dans un pod du cluster kubernetes il faut lire le fichier /var/run/secrets/kubernetes.io/serviceaccount/token\n",
    "# N√©anmoins ce param√®tre est inutile car le contexte kubernetes local de ce notebook est pr√©configur√©\n",
    "# conf.set(\"spark.kubernetes.authenticate.driver.serviceAccountName\", os.environ['KUBERNETES_SERVICE_ACCOUNT']) \n",
    "\n",
    "# Nom du namespace kubernetes\n",
    "conf.set(\"spark.kubernetes.namespace\", os.environ['KUBERNETES_NAMESPACE'])\n",
    "\n",
    "# Nombre d'executeur spark, il se lancera autant de pods kubernetes que le nombre indiqu√©.\n",
    "conf.set(\"spark.executor.instances\", \"10\")\n",
    "\n",
    "# M√©moire allou√© √† la JVM\n",
    "# Attention par d√©faut le pod kubernetes aura une limite sup√©rieur qui d√©pend d'autres param√®tres.\n",
    "# On manipulera plus bas pour v√©rifier la limite de m√©moire totale d'un executeur\n",
    "conf.set(\"spark.executor.memory\", \"4g\")\n",
    "\n",
    "conf.set(\"spark.kubernetes.driver.pod.name\", os.environ['KUBERNETES_POD_NAME'])\n",
    "\n",
    "# Param√®tres d'enregistrement des logs spark d'application\n",
    "# Attention ce param√®tres n√©cessitent la cr√©ation d'un dossier spark-history. Spark ne le fait pas lui m√™me pour des raisons obscurs\n",
    "# import s3fs\n",
    "# endpoint = \"https://\"+os.environ['AWS_S3_ENDPOINT']\n",
    "# fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': endpoint})\n",
    "# fs.touch('s3://tm8enk/spark-history/.keep')\n",
    "# sparkconf.set(\"spark.eventLog.enabled\",\"true\")\n",
    "# sparkconf.set(\"spark.eventLog.dir\",\"s3a://tm8enk/spark-history\")\n",
    "#ici pour g√©rer le dateTimeFormatter d√©pendant de la verion de java...\n",
    "conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\")\n",
    "conf.set(\"spark.default.parallelism\",10)\n",
    "conf.set(\"spark.sql.shuffle.partitions\",10)\n",
    "conf.set(\"spark.jars.packages\",\"graphframes:graphframes:0.8.1-spark3.0-s_2.12\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On note que :\n",
    "* on a pris 10 executeurs et on surcharge spark pour, lors de shuffle ou repartition, que son niveau de parallelisme soit 10 plutot que 200\n",
    "* on importe un jar au d√©marrage il va aller le chercher sur maven central, ce jar sera appell√© par la librairie python graphFrames √† travers Py4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"graph\").config(conf = conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphframes\n",
      "  Downloading graphframes-0.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting nose\n",
      "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154 kB 5.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from graphframes) (1.18.1)\n",
      "Installing collected packages: nose, graphframes\n",
      "Successfully installed graphframes-0.6 nose-1.3.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install graphframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constitution d'un graphe\n",
    "\n",
    "Un graphe peut √™tre vu comme 2 datasets:\n",
    "* Un **dataset de noeud** avec 2 colonnes : un identifiant et un attribut.\n",
    "* Un **dataset d'arcs** reliant 2 noeuds : avec un identifiant de noeud source, un destination et un ou des attributs sur cet arc\n",
    " \n",
    "A partir de ces 2 datasets que spark peut traiter comme des rdd √† travers le cluster, on peut travailler sur un graphe, voici un exemple simple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphframes import *\n",
    "\n",
    "vertices = [(1,\"A\"), (2,\"B\"), (3, \"C\")]\n",
    "edges = [(1,2,\"love\"), (2,1,\"hate\"), (2,3,\"follow\")]\n",
    "\n",
    "v = spark.createDataFrame(vertices, [\"id\", \"name\"])\n",
    "e = spark.createDataFrame(edges, [\"src\", \"dst\", \"action\"])\n",
    "\n",
    "premierGraphe = GraphFrame(v, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------+\n",
      "|src|dst|action|\n",
      "+---+---+------+\n",
      "|  1|  2|  love|\n",
      "|  2|  1|  hate|\n",
      "|  2|  3|follow|\n",
      "+---+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "premierGraphe.edges.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faisons un graphe sur les donn√©es twitter concernant l'insee\n",
    "\n",
    "Attention les donn√©es sont aliment√©es et √† la r√©execution du notebook les √©l√©ments suivants auront peut-√™tre √©volu√©s, on peut filtrer sur la date des tweets si n√©cessaire avant le 16 avril pour retrouver le d√©roul√© ci-dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on importe le schema\n",
    "import pickle\n",
    "schema = pickle.load( open( \"./7-streaming/schema.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on lit les donnn√©es\n",
    "df = spark.read.format(\"json\")  \\\n",
    "    .schema(schema) \\\n",
    "    .load(\"s3a://projet-spark-lab/diffusion/tweets/input\") \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons de cr√©er le graph des tweets mentionnant l'insee avec comme noeud les user de twitter et comme arc, 2 utilisateurs sont reli√©s si l'√©metteur du tweet a metionn√© un autre utilisateur dans le tweet\n",
    "\n",
    "Par exemple si alice tweet \"@bob tu vas vu le dernier tweet de l'Insee\" le noeud alice sera reli√© -> √† bob.\n",
    "\n",
    "Nous avons de la chance les donn√©es de l'api twitter pr√©mache le travail.\n",
    "\n",
    "Regardons pour commencer dans le tweet de l'api twitter les donn√©es suivantes:\n",
    "* l'identififiant du tweet\n",
    "* l'identifiant de l'utilisateur qui tweete\n",
    "* son nombre de followers pour savoir s'il est influent\n",
    "* la liste des hashtags pr√©sents dans le tweet (d√©j√† donn√© par twitter)\n",
    "* une indicatrice pour savoir s'il y a des hashtag \n",
    "* le texte du tweet\n",
    "* les user mentionn√©s dans le tweet sous forme de tableau (identifiant, name, screen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=1380418192426860546, user_id=219397176, name='Isabelle Hinden', followers_count=1633, hashtags=['immigr√©s'], has_hashtag=1, text='RT @InseeFr: En 2017, 44 % de la hausse de la population provient des #immigr√©s, soit 139\\xa0000 personnes. Depuis 2006, cette contribution √†‚Ä¶', user_mentions=[Row(id=217473382, id_str='217473382', indices=[3, 11], name='Insee', screen_name='InseeFr')])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,explode,size,first\n",
    "#.select(\"id\",\"user.id\",\"user.name\",\"user.followers_count\",\"entities.hashtags\",\"text\")\n",
    "df.select(col(\"id\").alias(\"id\"),\n",
    "         col(\"user.id\").alias(\"user_id\"),\n",
    "         col(\"user.name\").alias(\"name\"),\n",
    "         col(\"user.followers_count\"),\n",
    "         col(\"entities.hashtags.text\").alias(\"hashtags\"),\n",
    "         size(\"entities.hashtags\").alias(\"has_hashtag\"),\n",
    "         col(\"text\"),\n",
    "         col(\"entities.user_mentions\")) \\\n",
    " .filter(col(\"has_hashtag\")>0) \\\n",
    " .head(1) \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cr√©er le dataset des noeuds:\n",
    "* on r√©cup√©re les id et noms des √©metteurs de tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vertices\n",
    "tweeters=df.select(col(\"user.id\").alias(\"id\"), col(\"user.name\").alias(\"name\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On r√©cup√®re les id et noms des user mentionn√©s (m√™me s'ils n'ont pas forc√©ment twitt√©s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_mentionned=df.select(explode(col(\"entities.user_mentions\"))).select(col(\"col.id\").alias(\"id\"),col(\"col.screen_name\").alias(\"name\")).distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fait l'union des 2 dataframe et on va ne retenir qu'un nom (le nom dans la mention n'est pas toujours exact au nom du compte apparemment ca √©vitera les doublons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices=tweeters.union(users_mentionned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, collect_list\n",
    "# on d√©finit un udf qui prend le premier √©l√©ment\n",
    "udf_first = udf(lambda x: x[0])\n",
    "# on groupe l'union des deux dataset par id d'utilisateur et on collect \n",
    "#sous la forme d'une liste leurs noms qui peuvent diff√©rer entre les mentions et le compte\n",
    "# on applique l'udf pour ne retenir que le nom en t√™te\n",
    "\n",
    "final_vertices=vertices.groupby(\"id\").agg(udf_first(collect_list(\"name\")).alias(\"name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------------------------+\n",
      "|id      |name                                  |\n",
      "+--------+--------------------------------------+\n",
      "|4898091 |FinancialTimes                        |\n",
      "|7540072 |neufmetres                            |\n",
      "|10575072|Webzine de la dracenie et du Var Est ŸÜ|\n",
      "|16683666|spectator                             |\n",
      "|17385313|Julien_W                              |\n",
      "|17437184|alphoenix                             |\n",
      "|17464719|PascalR                               |\n",
      "|17779850|Jennifer Ogor                         |\n",
      "|18976358|SylvainePascual                       |\n",
      "|19713578|chris dabin                           |\n",
      "+--------+--------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_vertices.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faisons maintenant le dataset des arcs :\n",
    "* on prend l'identifiant de l'√©metteur\n",
    "* on prend duplique/explose la ligne pour avoir une ligne par mention dans le tweet\n",
    "* on r√©cup√®re les hashtags\n",
    "* on r√©cup√®re l'identifiant du tweet\n",
    "\n",
    "on group by user_id et mention.id (user mentionn√©) et on agggr√®ge pour avoir :\n",
    "* le nombre de tweets\n",
    "* la liste des hashtags vus entre ces 2 users dans le sens user_id -> mention.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count,collect_list,flatten\n",
    "edges=df.select(col(\"user.id\").alias(\"user_id\"), \\\n",
    "               explode(col(\"entities.user_mentions\")).alias(\"mention\"),\n",
    "               col(\"entities.hashtags.text\").alias(\"hashtags\"),\n",
    "               \"id\") \\\n",
    " .groupby(col(\"user_id\").alias(\"src\"), \\\n",
    "          col(\"mention.id\").alias(\"dst\")) \\\n",
    " .agg(count(\"id\").alias(\"nb\"),\n",
    "      flatten(collect_list(\"hashtags\")).alias(\"hashtags\"),\n",
    "      collect_list(\"id\").alias(\"id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+---+--------------------+--------------------+\n",
      "|     src|               dst| nb|            hashtags|                  id|\n",
      "+--------+------------------+---+--------------------+--------------------+\n",
      "|15217683|793749212118867969|  1|                  []|[1380995523168120...|\n",
      "|15872615|         121468512|  1|                  []|[1380245558141591...|\n",
      "|16600674|         217473382|  6|                  []|[1380505509611069...|\n",
      "|17193568|         217473382|  1|          [immigr√©s]|[1380513459482337...|\n",
      "|17385313|         217473382|  6|                  []|[1380247279894986...|\n",
      "|17464719|        2515649016|  1|                  []|[1380436148057608...|\n",
      "|18629937|         121468512|  1|                  []|[1380492059690295...|\n",
      "|18969131|          20947741|  1|                  []|[1380468019009355...|\n",
      "|19377400|         112754792|  1|                  []|[1381174506446848...|\n",
      "|20064944|        1460135654|  1|                  []|[1380449540738850...|\n",
      "|20181221|          46375782|  1|                  []|[1381281068037369...|\n",
      "|20181221|        1325327106|  1|                  []|[1381281068037369...|\n",
      "|20773587|          26073581|  2|                  []|[1381742535253573...|\n",
      "|20773587|         305783924|  2|                  []|[1381742535253573...|\n",
      "|21040954|          15618138|  1|                  []|[1380511284807012...|\n",
      "|22662958|          97514372|  1|                  []|[1382931299300704...|\n",
      "|23931979|         103918784|  1|                  []|[1380485755651362...|\n",
      "|27016118|983334079981654016|  1|                  []|[1381295795186585...|\n",
      "|28111905|        1187428428|  1|[JDD, Arras, Gran...|[1381340432462970...|\n",
      "|36017082|793749212118867969|  1|                  []|[1380866702695669...|\n",
      "+--------+------------------+---+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edges.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cr√©er le graphe\n",
    "\n",
    "Ca y est on a nos 2 structures:\n",
    "* **identifiant**, name ici seul **identifiant** est n√©cessaire name vient donner plus d'infos on pourrait ajouter d'autres colonnes\n",
    "* **identifianttwittant(src), identifiantmentionn√©(dst)**, nombre de fois, liste de hashtags, liste des ids de tweets ici seul les 2 premiers identifiants sont n√©cessaires le reste donne du contexte qu'on pourrait utiliser sur les arcs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphframes import *\n",
    "g = GraphFrame(final_vertices, edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant qu'on a ce graphe on va le mettre en cache car nous allons le manipuler plusieurs fois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphFrame(v:[id: bigint, name: string], e:[src: bigint, dst: bigint ... 3 more fields])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le graphe a 8407 noeuds et 11423 arcs\n"
     ]
    }
   ],
   "source": [
    "print(\"le graphe a \"+ str(g.vertices.count()) +\" noeuds et \"+ str(g.edges.count()) + \" arcs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche des utilisateurs populaires\n",
    "\n",
    "On peut via l'api appliquer diff√©rents algorithmes, il est d'usage dans les graphes de traiter des notions suivantes :\n",
    "* la notion de degr√© (nombre de connexion d'un noeud)\n",
    "* la notion de triangle (triplet de noeud totalement connect√©)\n",
    "* la notion de chemin entre noeud\n",
    "\n",
    "L'algorithme pageRank est un algorithme qui est connu pour etre utilis√© dans les moteurs de recherche, il peut etre execut√© sur un graphe pour juger de la \"popularit√©\" d'un noeud.\n",
    "\n",
    "On s'attend √† ce que le comte de l'insee soit pas mal plac√©.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagerank = g.pageRank(resetProbability=0.15,tol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------------------------------------+------------------+\n",
      "|id                 |name                                              |pagerank          |\n",
      "+-------------------+--------------------------------------------------+------------------+\n",
      "|103918784          |David Lisnard                                     |917.3584687834675 |\n",
      "|217473382          |Insee                                             |600.8061601474191 |\n",
      "|983334079981654016 |Docteur Peter EL BAZE                             |149.12888199110637|\n",
      "|945473418          |Docteur Laurent Alexandre #JeSuisDoublementVaccin√©|147.51973826592192|\n",
      "|3373762791         |GWGoldnadel                                       |138.67006416773918|\n",
      "|793749212118867969 |Raphael Pradeau                                   |120.89617748694437|\n",
      "|1243542086860918785|FrontPopOff                                       |115.42839094804633|\n",
      "|382736141          |Enedis                                            |112.99675094123769|\n",
      "|20947741           |Fr√©d√©ric Bianchi                                  |70.79398229596002 |\n",
      "|1209500610787196929|ObservatoireID                                    |70.0362125440602  |\n",
      "|882991259249455104 |Romain                                            |64.11423919805802 |\n",
      "|814141682040111105 |JS_2ass                                           |64.11423919805802 |\n",
      "|485565224          |InedFr                                            |60.605597337374284|\n",
      "|82607099           |Barbara Serrano                                   |59.36675428454663 |\n",
      "|55509201           |gforestier                                        |52.692516812210336|\n",
      "|268227446          |datagouvfr                                        |52.585970059663204|\n",
      "|472412809          |f_philippot                                       |52.09475147832378 |\n",
      "|465995281          |Tobelive is back                                  |45.88950490102726 |\n",
      "|1325542737979056135|MB üá≤üáΩ                                           |45.38748673426592 |\n",
      "|1323679162746441730|Lechevalier xavier                                |42.44459114991851 |\n",
      "+-------------------+--------------------------------------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "pagerank.vertices.sort(desc(\"pagerank\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arf seulement 2√®me sur la p√©riode de temps David Lisnard le maire de Cannes a bien vol√© la vedette "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---+--------+---------------------+------+\n",
      "|src      |dst      |nb |hashtags|id                   |weight|\n",
      "+---------+---------+---+--------+---------------------+------+\n",
      "|103918784|103918784|1  |[]      |[1380509496284430336]|1.0   |\n",
      "+---------+---------+---+--------+---------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pagerank.edges.where((col(\"src\")==\"103918784\") ).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pagerank.edges.where((col(\"dst\")==\"103918784\") ).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "David lisnard n'a tweet√© qu'une fois mais il s'est fait mentionn√© 510 fois autour de ce tweet.\n",
    "\n",
    "https://twitter.com/davidlisnard/status/1380509496284430336"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut regarder les utilisateurs ayant le plus √©t√© mentionn√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+--------------------------------------------------+\n",
      "|id                |inDegree|name                                              |\n",
      "+------------------+--------+--------------------------------------------------+\n",
      "|217473382         |1178    |Insee                                             |\n",
      "|945473418         |582     |Docteur Laurent Alexandre #JeSuisDoublementVaccin√©|\n",
      "|3373762791        |562     |GWGoldnadel                                       |\n",
      "|103918784         |510     |David Lisnard                                     |\n",
      "|983334079981654016|410     |Docteur Peter EL BAZE                             |\n",
      "|793749212118867969|391     |Raphael Pradeau                                   |\n",
      "|472412809         |198     |f_philippot                                       |\n",
      "|978184280         |192     |Damien Rieu                                       |\n",
      "|217749896         |182     |MLP_officiel                                      |\n",
      "|87212906          |167     |ThierryMARIANI                                    |\n",
      "+------------------+--------+--------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.inDegrees.join(g.vertices,\"id\").orderBy(desc(\"inDegree\")).show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ou qui ont mentionn√© le plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+------------------------------------------------+\n",
      "|id                 |outDegree|name                                            |\n",
      "+-------------------+---------+------------------------------------------------+\n",
      "|702991804661112832 |22       |Ari Kouts                                       |\n",
      "|1244716894671732738|21       |Bonsens Claire                                  |\n",
      "|1359816991033458689|20       |Cris Finland                                    |\n",
      "|1580838720         |20       |Augusta Crochet üíôLRüá´üá∑üá¶üá≤                    |\n",
      "|1376154610998640650|19       |Nasty Estelle üá®üáµ‚ù§Ô∏è                            |\n",
      "|1180210966711156736|17       |29quovadis                                      |\n",
      "|1222491562824949763|16       |Jacques                                         |\n",
      "|1284473275184226304|16       |Antoine Sulo                                    |\n",
      "|1378687476697550852|16       |BouleBille                                      |\n",
      "|2464135300         |16       |Daniel pilotte de la BAROLLIERüåº‚öúÔ∏è‚ù£Ô∏èü¶Ö‚ò¶Ô∏èüáÆüá±üáµüá±|\n",
      "+-------------------+---------+------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.outDegrees.join(g.vertices,\"id\").orderBy(desc(\"outDegree\")).show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'api propose d'autres algorithmes permettant:\n",
    "* de clusteriser le graphe (connected ou strong connected components)\n",
    "* de rechercher des patterns ou chemin dans le graphe ce qui pourrait etre int√©ressant pour voir par exemple une chaine de retweet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin on peut nous m√™me cr√©er nos propres algorithmes pour cela l'api propose une m√©thode aggregate messages permettant d'envoyer un message de noeud et noeud et d√©finir l'aggregation √† retenir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est aussi possible d'utiliser d3.js dans une celle ipython et d'afficher le graphe en javascript todo un exemple ici\n",
    "https://bl.ocks.org/heybignick/3faf257bbbbc7743bb72310d03b86ee8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "    var script = document.createElement('script');\n",
       "    script.type = 'text/javascript';\n",
       "    script.src = '//d3js.org/d3.v6.min.js';\n",
       "    document.head.appendChild(script);\n",
       "    console.log(window.d3)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "    var script = document.createElement('script');\n",
    "    script.type = 'text/javascript';\n",
    "    script.src = '//d3js.org/d3.v6.min.js';\n",
    "    document.head.appendChild(script);\n",
    "    console.log(window.d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "var svg = d3.select(element)\n",
       "    .append(\"svg\")\n",
       "    .attr(\"width\", 300)\n",
       "    .attr(\"height\", 300);    \n",
       "\n",
       "svg.append(\"circle\")\n",
       "    .style(\"stroke\", \"gray\")\n",
       "    .style(\"fill\", \"cyan\")\n",
       "    .attr(\"r\", 130)\n",
       "    .attr(\"cx\", 150)\n",
       "    .attr(\"cy\", 150)\n",
       "    .transition()\n",
       "        .delay(100)\n",
       "        .duration(10000)  \n",
       "        .attr(\"r\", 10)\n",
       "        .attr(\"cx\", 150)\n",
       "        .style(\"fill\", \"blue\"); \n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Javascript\n",
    "svg_script = '''\n",
    "var svg = d3.select(element)\n",
    "    .append(\"svg\")\n",
    "    .attr(\"width\", 300)\n",
    "    .attr(\"height\", 300);    \n",
    "\n",
    "svg.append(\"circle\")\n",
    "    .style(\"stroke\", \"gray\")\n",
    "    .style(\"fill\", \"cyan\")\n",
    "    .attr(\"r\", 130)\n",
    "    .attr(\"cx\", 150)\n",
    "    .attr(\"cy\", 150)\n",
    "    .transition()\n",
    "        .delay(100)\n",
    "        .duration(10000)  \n",
    "        .attr(\"r\", 10)\n",
    "        .attr(\"cx\", 150)\n",
    "        .style(\"fill\", \"blue\"); \n",
    "'''\n",
    "\n",
    "Javascript(svg_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "  const data = {nodes : [{ id: \"Myriel\", group: 1},{ id: \"Myriel3\", group: 1}], \n",
       "  links : [{source: \"Myriel\", target: \"Myriel3\", value: 1}]}\n",
       "\n",
       "  const links = data.links.map(d => Object.create(d));\n",
       "  const nodes = data.nodes.map(d => Object.create(d));\n",
       "  const width=300;\n",
       "  const height=400;\n",
       "  const simulation = d3.forceSimulation(nodes)\n",
       "      .force(\"link\", d3.forceLink(links).id(d => d.id))\n",
       "      .force(\"charge\", d3.forceManyBody())\n",
       "      .force(\"center\", d3.forceCenter(width / 2, height / 2));\n",
       "\n",
       "  const svg = d3.create(\"svg\")\n",
       "      .attr(\"viewBox\", [0, 0, width, height]);\n",
       "\n",
       "  const link = svg.append(\"g\")\n",
       "      .attr(\"stroke\", \"#999\")\n",
       "      .attr(\"stroke-opacity\", 0.6)\n",
       "    .selectAll(\"line\")\n",
       "    .data(links)\n",
       "    .join(\"line\")\n",
       "      .attr(\"stroke-width\", d => Math.sqrt(d.value));\n",
       "\n",
       "  function color ()  {\n",
       "      const scale = d3.scaleOrdinal(d3.schemeCategory10);\n",
       "      return d => scale(d.group);\n",
       "  }\n",
       "  \n",
       "  function drag (simulation) {\n",
       "  \n",
       "  function dragstarted(event) {\n",
       "    if (!event.active) simulation.alphaTarget(0.3).restart();\n",
       "    event.subject.fx = event.subject.x;\n",
       "    event.subject.fy = event.subject.y;\n",
       "  }\n",
       "  \n",
       "  function dragged(event) {\n",
       "    event.subject.fx = event.x;\n",
       "    event.subject.fy = event.y;\n",
       "  }\n",
       "  \n",
       "  function dragended(event) {\n",
       "    if (!event.active) simulation.alphaTarget(0);\n",
       "    event.subject.fx = null;\n",
       "    event.subject.fy = null;\n",
       "  }\n",
       "  \n",
       "  return d3.drag()\n",
       "      .on(\"start\", dragstarted)\n",
       "      .on(\"drag\", dragged)\n",
       "      .on(\"end\", dragended);\n",
       "    }\n",
       "  \n",
       "  const node = svg.append(\"g\")\n",
       "      .attr(\"stroke\", \"#fff\")\n",
       "      .attr(\"stroke-width\", 1.5)\n",
       "    .selectAll(\"circle\")\n",
       "    .data(nodes)\n",
       "    .join(\"circle\")\n",
       "      .attr(\"r\", 5)\n",
       "      .attr(\"fill\", color)\n",
       "      .call(drag(simulation));\n",
       "\n",
       "  node.append(\"title\")\n",
       "      .text(d => d.id);\n",
       "\n",
       "  simulation.on(\"tick\", () => {\n",
       "    link\n",
       "        .attr(\"x1\", d => d.source.x)\n",
       "        .attr(\"y1\", d => d.source.y)\n",
       "        .attr(\"x2\", d => d.target.x)\n",
       "        .attr(\"y2\", d => d.target.y);\n",
       "\n",
       "    node\n",
       "        .attr(\"cx\", d => d.x)\n",
       "        .attr(\"cy\", d => d.y);\n",
       "  });\n",
       "\n",
       " \n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Javascript\n",
    "svg_script = '''\n",
    "  const data = {nodes : [{ id: \"Myriel\", group: 1},{ id: \"Myriel3\", group: 1}], \n",
    "  links : [{source: \"Myriel\", target: \"Myriel3\", value: 1}]}\n",
    "\n",
    "  const links = data.links.map(d => Object.create(d));\n",
    "  const nodes = data.nodes.map(d => Object.create(d));\n",
    "  const width=300;\n",
    "  const height=400;\n",
    "  const simulation = d3.forceSimulation(nodes)\n",
    "      .force(\"link\", d3.forceLink(links).id(d => d.id))\n",
    "      .force(\"charge\", d3.forceManyBody())\n",
    "      .force(\"center\", d3.forceCenter(width / 2, height / 2));\n",
    "\n",
    "  const svg = d3.create(\"svg\")\n",
    "      .attr(\"viewBox\", [0, 0, width, height]);\n",
    "\n",
    "  const link = svg.append(\"g\")\n",
    "      .attr(\"stroke\", \"#999\")\n",
    "      .attr(\"stroke-opacity\", 0.6)\n",
    "    .selectAll(\"line\")\n",
    "    .data(links)\n",
    "    .join(\"line\")\n",
    "      .attr(\"stroke-width\", d => Math.sqrt(d.value));\n",
    "\n",
    "  function color ()  {\n",
    "      const scale = d3.scaleOrdinal(d3.schemeCategory10);\n",
    "      return d => scale(d.group);\n",
    "  }\n",
    "  \n",
    "  function drag (simulation) {\n",
    "  \n",
    "  function dragstarted(event) {\n",
    "    if (!event.active) simulation.alphaTarget(0.3).restart();\n",
    "    event.subject.fx = event.subject.x;\n",
    "    event.subject.fy = event.subject.y;\n",
    "  }\n",
    "  \n",
    "  function dragged(event) {\n",
    "    event.subject.fx = event.x;\n",
    "    event.subject.fy = event.y;\n",
    "  }\n",
    "  \n",
    "  function dragended(event) {\n",
    "    if (!event.active) simulation.alphaTarget(0);\n",
    "    event.subject.fx = null;\n",
    "    event.subject.fy = null;\n",
    "  }\n",
    "  \n",
    "  return d3.drag()\n",
    "      .on(\"start\", dragstarted)\n",
    "      .on(\"drag\", dragged)\n",
    "      .on(\"end\", dragended);\n",
    "    }\n",
    "  \n",
    "  const node = svg.append(\"g\")\n",
    "      .attr(\"stroke\", \"#fff\")\n",
    "      .attr(\"stroke-width\", 1.5)\n",
    "    .selectAll(\"circle\")\n",
    "    .data(nodes)\n",
    "    .join(\"circle\")\n",
    "      .attr(\"r\", 5)\n",
    "      .attr(\"fill\", color)\n",
    "      .call(drag(simulation));\n",
    "\n",
    "  node.append(\"title\")\n",
    "      .text(d => d.id);\n",
    "\n",
    "  simulation.on(\"tick\", () => {\n",
    "    link\n",
    "        .attr(\"x1\", d => d.source.x)\n",
    "        .attr(\"y1\", d => d.source.y)\n",
    "        .attr(\"x2\", d => d.target.x)\n",
    "        .attr(\"y2\", d => d.target.y);\n",
    "\n",
    "    node\n",
    "        .attr(\"cx\", d => d.x)\n",
    "        .attr(\"cy\", d => d.y);\n",
    "  });\n",
    "\n",
    " \n",
    "'''\n",
    "\n",
    "Javascript(svg_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
